{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_AE 원본.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNaoSaozeJYBhYsk7dnbqjy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neisyo-korea/chobo-s-tear/blob/main/LSTM_AE_%EC%9B%90%EB%B3%B8%EC%BD%94%EB%93%9C%EC%99%80%20%EB%B3%80%EA%B2%BD%ED%95%9C%EB%B6%80%EB%B6%84%EB%93%A4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import easydict\n",
        "from tqdm.notebook import trange, tqdm\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "'''from celluloid import Camera''' #삭제, 가동이 안됨.\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from typing import List \n",
        "#https://joungheekim.github.io/2020/11/14/code-review/"
      ],
      "metadata": {
        "id": "ezDCJPtmrTtw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "LeEDuNE4rIPy",
        "outputId": "55c50723-5863-4889-ae6c-dc108641736f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Time (min)       X1           X2           X3      X4         X5         X6  \\\n",
              "0           0.24889  3702.300049  4502.700195  9.4170  26.996000  42.182999   \n",
              "1           0.24904  3666.199951  4526.000000  9.2682  26.709999  42.332001   \n",
              "2           0.25034  3673.300049  4501.299805  9.4212  26.841999  42.360001   \n",
              "3           0.25109  3657.800049  4497.799805  9.3792  26.528000  41.981998   \n",
              "4           0.24563  3698.000000  4537.399902  9.3746  26.736000  42.354000   \n",
              "\n",
              "Time (min)           X7         X8          X9      X10  ...        X43  \\\n",
              "0           2705.199951  75.172997  120.400002  0.33611  ...  54.058998   \n",
              "1           2705.500000  74.411003  120.410004  0.33676  ...  53.780998   \n",
              "2           2705.300049  75.125000  120.410004  0.33739  ...  54.075001   \n",
              "3           2707.300049  73.991997  120.379997  0.33664  ...  54.117001   \n",
              "4           2705.300049  75.282997  120.419998  0.32521  ...  53.905998   \n",
              "\n",
              "Time (min)        X44        X45        X46        X47        X48        X49  \\\n",
              "0           24.804001  63.269001  21.950001  40.188000  39.460999  47.000000   \n",
              "1           24.790001  62.171001  22.239000  40.108002  43.709999  46.127998   \n",
              "2           24.669001  61.584999  22.191000  40.029999  39.480000  44.120998   \n",
              "3           24.594999  61.561001  21.959000  40.120998  32.848000  45.858002   \n",
              "4           24.451000  61.388000  22.271000  39.537998  36.681999  45.752998   \n",
              "\n",
              "Time (min)        X50        X51        X52  \n",
              "0           47.594002  41.383999  18.905001  \n",
              "1           47.507999  41.658001  18.976000  \n",
              "2           47.612000  41.721001  16.562000  \n",
              "3           47.459000  40.835999  20.094000  \n",
              "4           47.458000  41.727001  18.330000  \n",
              "\n",
              "[5 rows x 52 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d36930c2-cda9-4bd6-ab89-390f8f0ac94e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Time (min)</th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X5</th>\n",
              "      <th>X6</th>\n",
              "      <th>X7</th>\n",
              "      <th>X8</th>\n",
              "      <th>X9</th>\n",
              "      <th>X10</th>\n",
              "      <th>...</th>\n",
              "      <th>X43</th>\n",
              "      <th>X44</th>\n",
              "      <th>X45</th>\n",
              "      <th>X46</th>\n",
              "      <th>X47</th>\n",
              "      <th>X48</th>\n",
              "      <th>X49</th>\n",
              "      <th>X50</th>\n",
              "      <th>X51</th>\n",
              "      <th>X52</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.24889</td>\n",
              "      <td>3702.300049</td>\n",
              "      <td>4502.700195</td>\n",
              "      <td>9.4170</td>\n",
              "      <td>26.996000</td>\n",
              "      <td>42.182999</td>\n",
              "      <td>2705.199951</td>\n",
              "      <td>75.172997</td>\n",
              "      <td>120.400002</td>\n",
              "      <td>0.33611</td>\n",
              "      <td>...</td>\n",
              "      <td>54.058998</td>\n",
              "      <td>24.804001</td>\n",
              "      <td>63.269001</td>\n",
              "      <td>21.950001</td>\n",
              "      <td>40.188000</td>\n",
              "      <td>39.460999</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>47.594002</td>\n",
              "      <td>41.383999</td>\n",
              "      <td>18.905001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.24904</td>\n",
              "      <td>3666.199951</td>\n",
              "      <td>4526.000000</td>\n",
              "      <td>9.2682</td>\n",
              "      <td>26.709999</td>\n",
              "      <td>42.332001</td>\n",
              "      <td>2705.500000</td>\n",
              "      <td>74.411003</td>\n",
              "      <td>120.410004</td>\n",
              "      <td>0.33676</td>\n",
              "      <td>...</td>\n",
              "      <td>53.780998</td>\n",
              "      <td>24.790001</td>\n",
              "      <td>62.171001</td>\n",
              "      <td>22.239000</td>\n",
              "      <td>40.108002</td>\n",
              "      <td>43.709999</td>\n",
              "      <td>46.127998</td>\n",
              "      <td>47.507999</td>\n",
              "      <td>41.658001</td>\n",
              "      <td>18.976000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.25034</td>\n",
              "      <td>3673.300049</td>\n",
              "      <td>4501.299805</td>\n",
              "      <td>9.4212</td>\n",
              "      <td>26.841999</td>\n",
              "      <td>42.360001</td>\n",
              "      <td>2705.300049</td>\n",
              "      <td>75.125000</td>\n",
              "      <td>120.410004</td>\n",
              "      <td>0.33739</td>\n",
              "      <td>...</td>\n",
              "      <td>54.075001</td>\n",
              "      <td>24.669001</td>\n",
              "      <td>61.584999</td>\n",
              "      <td>22.191000</td>\n",
              "      <td>40.029999</td>\n",
              "      <td>39.480000</td>\n",
              "      <td>44.120998</td>\n",
              "      <td>47.612000</td>\n",
              "      <td>41.721001</td>\n",
              "      <td>16.562000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.25109</td>\n",
              "      <td>3657.800049</td>\n",
              "      <td>4497.799805</td>\n",
              "      <td>9.3792</td>\n",
              "      <td>26.528000</td>\n",
              "      <td>41.981998</td>\n",
              "      <td>2707.300049</td>\n",
              "      <td>73.991997</td>\n",
              "      <td>120.379997</td>\n",
              "      <td>0.33664</td>\n",
              "      <td>...</td>\n",
              "      <td>54.117001</td>\n",
              "      <td>24.594999</td>\n",
              "      <td>61.561001</td>\n",
              "      <td>21.959000</td>\n",
              "      <td>40.120998</td>\n",
              "      <td>32.848000</td>\n",
              "      <td>45.858002</td>\n",
              "      <td>47.459000</td>\n",
              "      <td>40.835999</td>\n",
              "      <td>20.094000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.24563</td>\n",
              "      <td>3698.000000</td>\n",
              "      <td>4537.399902</td>\n",
              "      <td>9.3746</td>\n",
              "      <td>26.736000</td>\n",
              "      <td>42.354000</td>\n",
              "      <td>2705.300049</td>\n",
              "      <td>75.282997</td>\n",
              "      <td>120.419998</td>\n",
              "      <td>0.32521</td>\n",
              "      <td>...</td>\n",
              "      <td>53.905998</td>\n",
              "      <td>24.451000</td>\n",
              "      <td>61.388000</td>\n",
              "      <td>22.271000</td>\n",
              "      <td>39.537998</td>\n",
              "      <td>36.681999</td>\n",
              "      <td>45.752998</td>\n",
              "      <td>47.458000</td>\n",
              "      <td>41.727001</td>\n",
              "      <td>18.330000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 52 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d36930c2-cda9-4bd6-ab89-390f8f0ac94e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d36930c2-cda9-4bd6-ab89-390f8f0ac94e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d36930c2-cda9-4bd6-ab89-390f8f0ac94e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "df = pd.read_csv('/content/Train.csv', index_col=0)\n",
        "#데이터셋의 인덱스와 피처란이 불편하게 있어서 이쁘게 바꿈.\n",
        "new_header = df.iloc[0] \n",
        "df = df[1:] \n",
        "df.columns = new_header \n",
        "df = df.astype(float) # str오류 뜨길래 첨부터 숫자열로 변경\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''def plot_sensor(temp_df, save_path='sample.gif'):\n",
        "    fig = plt.figure(figsize=(16, 6))\n",
        "    ## 에니메이션 만들기\n",
        "    camera = Camera(fig)\n",
        "    ax=fig.add_subplot(111)\n",
        "    \n",
        "    ## 불량 구간 탐색 데이터\n",
        "    labels = temp_df['machine_status'].values.tolist()\n",
        "    dates = temp_df.index\n",
        "    \n",
        "    for var_name in tqdm([item for item in df.columns if 'sensor_' in item]):\n",
        "        ## 센서별로 사진 찍기\n",
        "        temp_df[var_name].plot(ax=ax)\n",
        "        ax.legend([var_name], loc='upper right')\n",
        "        \n",
        "        ## 고장구간 표시\n",
        "        temp_start = dates[0]\n",
        "        temp_date = dates[0]\n",
        "        temp_label = labels[0]\n",
        "        \n",
        "        for xc, value in zip(dates, labels):\n",
        "            if temp_label != value:\n",
        "                if temp_label == \"BROKEN\":\n",
        "                    ax.axvspan(temp_start, temp_date, alpha=0.2, color='blue')\n",
        "                if temp_label == \"RECOVERING\":\n",
        "                    ax.axvspan(temp_start, temp_date, alpha=0.2, color='orange')\n",
        "                temp_start=xc\n",
        "                temp_label=value\n",
        "            temp_date = xc\n",
        "        if temp_label == \"BROKEN\":\n",
        "            ax.axvspan(temp_start, xc, alpha=0.2, color='blue')\n",
        "        if temp_label == \"RECOVERING\":\n",
        "            ax.axvspan(temp_start, xc, alpha=0.2, color='orange')\n",
        "        ## 카메라 찍기\n",
        "        camera.snap()\n",
        "        \n",
        "    animation = camera.animate(500, blit=True)\n",
        "    # .gif 파일로 저장하면 끝!\n",
        "    animation.save(\n",
        "        save_path,\n",
        "        dpi=100,\n",
        "        savefig_kwargs={\n",
        "            'frameon': False,\n",
        "            'pad_inches': 'tight'\n",
        "        }\n",
        "    )\n",
        "plot_sensor(df)''' #카메라 모듈 없어서 코드 삭제. + 데이터 보는게 의미가 없음."
      ],
      "metadata": {
        "id": "3hjr659VrQs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 전처리(필요없어서 코드 지움)"
      ],
      "metadata": {
        "id": "Irdat4rxtQkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "## 데이터 Type 변경\n",
        "df['date'] = pd.to_datetime(df['timestamp'])\n",
        "for var_index in [item for item in df.columns if 'sensor_' in item]:\n",
        "    df[var_index] = pd.to_numeric(df[var_index], errors='coerce')\n",
        "del df['timestamp']\n",
        "\n",
        "## date를 index로 변환\n",
        "df = df.set_index('date')\n",
        "''' # 데이터 불러올때 이미 time을 index로 둬서 코드 삭제함."
      ],
      "metadata": {
        "id": "9HO8BjUVr66l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "## 결측 변수 확인\n",
        "(df.isnull().sum()/len(df)).plot.bar(figsize=(18, 8), colormap='Paired')\n",
        "'''#결측 변수 없어서 코드 삭제.\n",
        "'''\n",
        "## 중복된 데이터를 삭제\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "## 센서 15번, 센서 50 은 삭제\n",
        "del df['sensor_15']\n",
        "del df['sensor_50']\n",
        "\n",
        "## 이전 시점의 데이터로 보간\n",
        "df.fillna(method='ffill')\n",
        "'''#보간 필요없어서 지움."
      ],
      "metadata": {
        "id": "OOpvOuyXtGvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 분리 및 정규화 하기"
      ],
      "metadata": {
        "id": "qph1B3q7tpeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터셋 자체가 전부 노말이라 분리 안했음.\n",
        "\n",
        "normal_df = df\n",
        "'''\n",
        "abnormal_df = df[df['machine_status']!='NORMAL']\n",
        "''' # 코드 제거."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "WRuUiwoPtlJ4",
        "outputId": "643ff817-9ee6-487d-87b3-4329caf2823a"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nabnormal_df = df[df['machine_status']!='NORMAL']\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 시계열 데이터이고, 입력의 형태가 특정 길이(window size)의 sequence 데이터 이므로 shuffle은 사용하지 않습니다.\n",
        "## Normal 데이터는 학습데이터, 파라미터 설정데이터, 검증용데이터, 실험용데이터의 비율을 7:1:1:1 로 나누어서 사용합니다.\n",
        "\n",
        "interval_n = int(len(normal_df)/10)\n",
        "normal_df1 = df.iloc[0:interval_n*7]\n",
        "normal_df2 = df.iloc[interval_n*7:interval_n*8]\n",
        "normal_df3 = df.iloc[interval_n*8:interval_n*9]\n",
        "normal_df4 = df.iloc[interval_n*9:]\n",
        "'''\n",
        "## abnormal 데이터는 검증용데이터, 실험용데이터의 비율을 5:5 로 나누어서 사용합니다.\n",
        "interval_ab = int(len(abnormal_df)/2)\n",
        "abnormal_df1 = df.iloc[0:interval_ab]\n",
        "abnormal_df2 = df.iloc[interval_ab:]\n",
        "'''#abnormal 없어서 제거함.  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "1MJJv_12uNJe",
        "outputId": "da98a33d-3faa-4a61-fdd9-6880a4e99b53"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n## abnormal 데이터는 검증용데이터, 실험용데이터의 비율을 5:5 로 나누어서 사용합니다.\\ninterval_ab = int(len(abnormal_df)/2)\\nabnormal_df1 = df.iloc[0:interval_ab]\\nabnormal_df2 = df.iloc[interval_ab:]\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 데이터 정규화를 위하여 분산 및 평균 추출\n",
        "mean_df = normal_df1.mean()\n",
        "std_df = normal_df1.std()"
      ],
      "metadata": {
        "id": "xP1F1XBpu92H"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "## 데이터를 불러올 때 index로 불러오기\n",
        "def make_data_idx(dates, window_size=1):\n",
        "    input_idx = []\n",
        "    for idx in range(window_size-1, len(dates)):\n",
        "        cur_date = dates[idx].to_pydatetime()\n",
        "        in_date = dates[idx - (window_size-1)].to_pydatetime()\n",
        "        \n",
        "        _in_period = (cur_date - in_date).days * 24 * 60 + (cur_date - in_date).seconds / 60\n",
        "        \n",
        "        ## 각 index가 1분 간격으로 떨어져 있는지를 확인합니다.\n",
        "        if _in_period == (window_size-1):\n",
        "            input_idx.append(list(range(idx - window_size+1, idx+1)))\n",
        "    return input_idx\n",
        "''' #원래 Index의 순으로 들어가지 않나? 싶어서 지움."
      ],
      "metadata": {
        "id": "ffRyCfkHvAoF"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Dataset을 상속받아 데이터를 구성\n",
        "class TagDataset(Dataset):\n",
        "    def __init__(self, input_size, df, mean_df=None, std_df = None, window_size=1):\n",
        "        \n",
        "        ## 변수 갯수\n",
        "        self.input_size = input_size\n",
        "        \n",
        "        ## 복원할 sequence 길이\n",
        "        self.window_size = window_size\n",
        "        \n",
        "        ## Summary용 데이터 Deep copy\n",
        "        original_df = df.copy()\n",
        "        '''\n",
        "        정규화에서 데이터 열이 X1~52라 원본코드 sensor로 적혀있는 부분 X로 변경 \n",
        "        '''\n",
        "        ## 정규화\n",
        "        if mean_df is not None and std_df is not None:\n",
        "            sensor_columns = [item for item in df.columns if '\bX' in item] # << 요기\n",
        "            df[sensor_columns] = (df[sensor_columns]-mean_df)/std_df\n",
        "        \n",
        "        '''\n",
        "        ## 연속한 index를 기준으로 학습에 사용합니다.\n",
        "        dates = list(df['date'])\n",
        "        self.input_ids = make_data_idx(dates, window_size=window_size)\n",
        "        '''\n",
        "        #을 아래와 같이 바꿈 make 함수도 지워서 없고 어차피 인덱스 기준으로 들어가기만 하면 상관없어서?...\n",
        "        dates = list(df.index)\n",
        "        self.input_ids = df.index\n",
        "\n",
        "        ## sensor 데이터만 사용하여 reconstruct에 활용\n",
        "        self.selected_column = [item for item in df.columns if '\bX' in item][:input_size] # << 요기도 X수정\n",
        "        self.var_data = torch.tensor(df[self.selected_column].values, dtype=torch.float)\n",
        "        \n",
        "        ## Summary 용\n",
        "        self.df = original_df.iloc[np.array(self.input_ids)[:, -1]]\n",
        "        \n",
        "    ## Dataset은 반드시 __len__ 함수를 만들어줘야함(데이터 길이)\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "    \n",
        "    ## Dataset은 반드시 __getitem__ 함수를 만들어줘야함\n",
        "    ## torch 모듈은 __getitem__ 을 호출하여 학습할 데이터를 불러옴.\n",
        "    def __getitem__(self, item):\n",
        "        temp_input_ids = self.input_ids[item]\n",
        "        input_values = self.var_data[temp_input_ids]\n",
        "        return input_values"
      ],
      "metadata": {
        "id": "QEaZrsdMvGyB"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 인코더\n",
        "class Encoder(nn.Module):\n",
        "\n",
        "    '''def __init__(self, input_size=4096, hidden_size=1024, num_layers=2):\n",
        "    ''' #원본코드의 숫자들을 변경\n",
        "    def __init__(self, input_size=52, hidden_size=13, num_layers=2):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True,\n",
        "                            dropout=0.1, bidirectional=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs, (hidden, cell) = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
        "\n",
        "        return (hidden, cell)\n",
        "    \n",
        "## 디코더\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "    '''def __init__(self, input_size=4096, hidden_size=1024, output_size=4096, num_layers=2):\n",
        "    ''' #또한 마찬가지.\n",
        "    def __init__(self, input_size=52, hidden_size=13, output_size=52, num_layers=2):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True,\n",
        "                            dropout=0.1, bidirectional=False)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        \n",
        "    def forward(self, x, hidden):\n",
        "        output, (hidden, cell) = self.lstm(x, hidden)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
        "        prediction = self.fc(output)\n",
        "\n",
        "        return prediction, (hidden, cell)\n",
        "    \n",
        "## LSTM Auto Encoder\n",
        "class LSTMAutoEncoder(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 input_dim: int,\n",
        "                 latent_dim: int,\n",
        "                 window_size: int=1,\n",
        "                 **kwargs) -> None:\n",
        "        \"\"\"\n",
        "        :param input_dim: 변수 Tag 갯수\n",
        "        :param latent_dim: 최종 압축할 차원 크기\n",
        "        :param window_size: 길이\n",
        "        :param kwargs:\n",
        "        \"\"\"\n",
        "\n",
        "        super(LSTMAutoEncoder, self).__init__()\n",
        "\n",
        "        self.latent_dim = latent_dim\n",
        "        self.input_dim = input_dim\n",
        "        self.window_size = window_size\n",
        "\n",
        "        if \"num_layers\" in kwargs:\n",
        "            num_layers = kwargs.pop(\"num_layers\")\n",
        "        else:\n",
        "            num_layers = 1\n",
        "\n",
        "        self.encoder = Encoder(\n",
        "            input_size=input_dim,\n",
        "            hidden_size=latent_dim,\n",
        "            num_layers=num_layers,\n",
        "        )\n",
        "        self.reconstruct_decoder = Decoder(\n",
        "            input_size=input_dim,\n",
        "            output_size=input_dim,\n",
        "            hidden_size=latent_dim,\n",
        "            num_layers=num_layers,\n",
        "        )\n",
        "\n",
        "    def forward(self, src:torch.Tensor, **kwargs):\n",
        "        batch_size, sequence_length, var_length = src.size()\n",
        "\n",
        "        ## Encoder 넣기\n",
        "        encoder_hidden = self.encoder(src)\n",
        "        \n",
        "        inv_idx = torch.arange(sequence_length - 1, -1, -1).long()\n",
        "        reconstruct_output = []\n",
        "        temp_input = torch.zeros((batch_size, 1, var_length), dtype=torch.float).to(src.device)\n",
        "        hidden = encoder_hidden\n",
        "        for t in range(sequence_length):\n",
        "            temp_input, hidden = self.reconstruct_decoder(temp_input, hidden)\n",
        "            reconstruct_output.append(temp_input)\n",
        "        reconstruct_output = torch.cat(reconstruct_output, dim=1)[:, inv_idx, :]\n",
        "        \n",
        "        return [reconstruct_output, src]\n",
        "\n",
        "    def loss_function(self,\n",
        "                      *args,\n",
        "                      **kwargs) -> dict:\n",
        "        recons = args[0]\n",
        "        input = args[1]\n",
        "        \n",
        "        ## MSE loss(Mean squared Error)\n",
        "        loss =F.mse_loss(recons, input)\n",
        "        return loss"
      ],
      "metadata": {
        "id": "Tva_5VuSvK-o"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run(args, model, train_loader, test_loader):\n",
        "    # optimizer 설정\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
        "\n",
        "    ## 반복 횟수 Setting\n",
        "    epochs = tqdm(range(args.max_iter//len(train_loader)+1))\n",
        "    \n",
        "    ## 학습하기\n",
        "    count = 0\n",
        "    best_loss = 100000000\n",
        "    for epoch in epochs:\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        train_iterator = tqdm(enumerate(train_loader), total=len(train_loader), desc=\"training\")\n",
        "\n",
        "        for i, batch_data in train_iterator:\n",
        "            \n",
        "            if count > args.max_iter:\n",
        "                return model\n",
        "            count += 1\n",
        "            \n",
        "            batch_data = batch_data.to(args.device)\n",
        "            predict_values = model(batch_data)\n",
        "            loss = model.loss_function(*predict_values)\n",
        "\n",
        "            # Backward and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            train_iterator.set_postfix({\n",
        "                \"train_loss\": float(loss),\n",
        "            })\n",
        "\n",
        "        model.eval()\n",
        "        eval_loss = 0\n",
        "        test_iterator = tqdm(enumerate(test_loader), total=len(test_loader), desc=\"testing\")\n",
        "        with torch.no_grad():\n",
        "            for i, batch_data in test_iterator:\n",
        "                \n",
        "                batch_data = batch_data.to(args.device)\n",
        "                predict_values = model(batch_data)\n",
        "                loss = model.loss_function(*predict_values)\n",
        "\n",
        "                eval_loss += loss.mean().item()\n",
        "\n",
        "                test_iterator.set_postfix({\n",
        "                    \"eval_loss\": float(loss),\n",
        "                })\n",
        "        eval_loss = eval_loss / len(test_loader)\n",
        "        epochs.set_postfix({\n",
        "             \"Evaluation Score\": float(eval_loss),\n",
        "        })\n",
        "        if eval_loss < best_loss:\n",
        "            best_loss = eval_loss\n",
        "        else:\n",
        "            if args.early_stop:\n",
        "                print('early stop condition   best_loss[{}]  eval_loss[{}]'.format(best_loss, eval_loss))\n",
        "                return model\n",
        "        \n",
        "    return model\n",
        "\n",
        "def get_loss_list(args, model, test_loader):\n",
        "    test_iterator = tqdm(enumerate(test_loader), total=len(test_loader), desc=\"testing\")\n",
        "    loss_list = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i, batch_data in test_iterator:\n",
        "                \n",
        "            batch_data = batch_data.to(args.device)\n",
        "            predict_values = model(batch_data)\n",
        "            \n",
        "            ## MAE(Mean Absolute Error)로 계산\n",
        "            loss = F.l1_loss(predict_values[0], predict_values[1], reduce=False)\n",
        "            #loss = loss.sum(dim=2).sum(dim=1).cpu().numpy()\n",
        "            loss = loss.mean(dim=1).cpu().numpy()\n",
        "            loss_list.append(loss)\n",
        "    loss_list = np.concatenate(loss_list, axis=0)\n",
        "    return loss_list"
      ],
      "metadata": {
        "id": "DsPiJknjvM8H"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 하이퍼 파라미터 설정\n",
        "args = easydict.EasyDict({\n",
        "    \"batch_size\": 128, ## 배치 사이즈 설정\n",
        "    \"device\": torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'), ## GPU 사용 여부 설정\n",
        "    \"input_size\": 52, ## 입력 차원 설정 \n",
        "                      '''변수 사이즈 40->52개라 바꿈 나머지 사이즈는 모두 동일'''\n",
        "    \"latent_size\": 10, ## Hidden 차원 설정\n",
        "    \"output_size\": 52, ## 출력 차원 설정\n",
        "    \"window_size\" : 3, ## sequence Lenght\n",
        "    \"num_layers\": 2,     ## LSTM layer 갯수 설정\n",
        "    \"learning_rate\" : 0.001, ## learning rate 설정\n",
        "    \"max_iter\" : 100000, ## 총 반복 횟수 설정\n",
        "    'early_stop' : True,  ## valid loss가 작아지지 않으면 early stop 조건 설정\n",
        "})"
      ],
      "metadata": {
        "id": "ClgJGclxvOil"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 데이터셋으로 변환\n",
        "normal_dataset1 = TagDataset(df=normal_df1, input_size=args.input_size, window_size=args.window_size, mean_df=mean_df, std_df=std_df)\n",
        "normal_dataset2 = TagDataset(df=normal_df2, input_size=args.input_size, window_size=args.window_size, mean_df=mean_df, std_df=std_df)\n",
        "normal_dataset3 = TagDataset(df=normal_df3, input_size=args.input_size, window_size=args.window_size, mean_df=mean_df, std_df=std_df)\n",
        "normal_dataset4 = TagDataset(df=normal_df4, input_size=args.input_size, window_size=args.window_size, mean_df=mean_df, std_df=std_df)\n",
        "\n",
        "'''\n",
        "abnormal_dataset1 = TagDataset(df=abnormal_df1, input_size=args.input_size, window_size=args.window_size, mean_df=mean_df, std_df=std_df)\n",
        "abnormal_dataset2 = TagDataset(df=abnormal_df2, input_size=args.input_size, window_size=args.window_size, mean_df=mean_df, std_df=std_df)\n",
        "''' \n",
        "#제거함"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "Rzs4GpezvQuq",
        "outputId": "599a1339-cfdf-49d5-9545-6dbf512a4ef7"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-b0059094011f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## 데이터셋으로 변환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnormal_dataset1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTagDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormal_df1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstd_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnormal_dataset2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTagDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormal_df2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstd_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnormal_dataset3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTagDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormal_df3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstd_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnormal_dataset4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTagDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormal_df4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstd_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-f9fb9f14ec4f>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_size, df, mean_df, std_df, window_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmean_df\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstd_df\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0msensor_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'\bX'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# << 요기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msensor_columns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msensor_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmean_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mstd_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         '''\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3598\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3599\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3600\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3601\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3602\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item_frame_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_setitem_array\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3637\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3638\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3639\u001b[0;31m                 \u001b[0mcheck_key_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3640\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3641\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexers.py\u001b[0m in \u001b[0;36mcheck_key_length\u001b[0;34m(columns, key, value)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Columns must be same length as key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;31m# Missing keys in columns are represented as -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Columns must be same length as key"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#이상하게 얜 왜 여기서 또 오류야 ㅠㅠㅠㅠㅠ "
      ],
      "metadata": {
        "id": "q3WJ0gfi2Fef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Data Loader 형태로 변환\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "                 dataset=normal_dataset1,\n",
        "                 batch_size=args.batch_size,\n",
        "                 shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(\n",
        "                dataset=normal_dataset2,\n",
        "                batch_size=args.batch_size,\n",
        "                shuffle=False)"
      ],
      "metadata": {
        "id": "3xgCKmX2vWwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 모델 생성\n",
        "model = LSTMAutoEncoder(input_dim=args.input_size, latent_dim=args.latent_size, window_size=args.window_size, num_layers=args.num_layers)\n",
        "model.to(args.device)"
      ],
      "metadata": {
        "id": "bcoBg0zl2BXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 학습하기\n",
        "model = run(args, model, train_loader, valid_loader)"
      ],
      "metadata": {
        "id": "XVRN1hiC2DjL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}